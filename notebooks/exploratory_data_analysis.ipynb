{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis for \"Dr≈æavni Posao\" Show\n",
    "\n",
    "## Importing Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setting plot aesthetics\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "## Data Loading and Initial Inspection\n",
    "\n",
    "# Load the data (replace 'drzavni_posao.csv' with your actual file path)\n",
    "df = pd.read_csv('drzavni_posao.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "display(df.dtypes)\n",
    "\n",
    "print(\"\\nSummary statistics for numerical columns:\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\nMissing values by column:\")\n",
    "display(df.isnull().sum())\n",
    "\n",
    "## Data Cleaning and Preprocessing\n",
    "\n",
    "# Function to extract duration in seconds from length column\n",
    "def convert_length_to_seconds(length):\n",
    "    if pd.isna(length):\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        parts = str(length).split(':')\n",
    "        if len(parts) == 2:  # MM:SS format\n",
    "            return int(parts[0]) * 60 + int(parts[1])\n",
    "        elif len(parts) == 3:  # HH:MM:SS format\n",
    "            return int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Convert length to seconds\n",
    "df['length_seconds'] = df['length'].apply(convert_length_to_seconds)\n",
    "\n",
    "# Convert date to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d.%m.%Y.', errors='coerce')\n",
    "\n",
    "# Extract episode number from title where missing\n",
    "def extract_episode_number(title):\n",
    "    if pd.isna(title):\n",
    "        return np.nan\n",
    "    \n",
    "    match = re.search(r'Ep\\.(\\d+)', str(title))\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return np.nan\n",
    "\n",
    "# Fill missing episode numbers\n",
    "if df['episode_number'].isnull().any():\n",
    "    df['episode_number'] = df.apply(\n",
    "        lambda x: extract_episode_number(x['title']) if pd.isna(x['episode_number']) else x['episode_number'], \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# Convert season and episode_number to integers where possible\n",
    "df['season'] = pd.to_numeric(df['season'], errors='coerce')\n",
    "\n",
    "# Create a category for special episodes\n",
    "df['is_special'] = df['title'].str.contains('specijal|proslava|atmosfera|jubilej', case=False, regex=True, na=False)\n",
    "\n",
    "# Check processed data\n",
    "print(\"\\nAfter preprocessing, first 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "### 1. Basic Statistics by Season\n",
    "\n",
    "# Count episodes per season\n",
    "season_counts = df['season'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x=season_counts.index, y=season_counts.values)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title('Number of Episodes per Season', fontsize=14)\n",
    "plt.xlabel('Season', fontsize=12)\n",
    "plt.ylabel('Number of Episodes', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Episode Length Analysis\n",
    "\n",
    "# Average episode length by season\n",
    "plt.figure(figsize=(12, 6))\n",
    "season_length = df.groupby('season')['length_seconds'].mean() / 60  # Convert to minutes\n",
    "ax = sns.barplot(x=season_length.index, y=season_length.values)\n",
    "ax.bar_label(ax.containers[0], fmt='%.1f')\n",
    "plt.title('Average Episode Length by Season (Minutes)', fontsize=14)\n",
    "plt.xlabel('Season', fontsize=12)\n",
    "plt.ylabel('Average Length (minutes)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of episode lengths\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.histplot(df['length_seconds']/60, bins=30, kde=True)\n",
    "plt.title('Distribution of Episode Lengths', fontsize=14)\n",
    "plt.xlabel('Length (minutes)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.axvline(df['length_seconds'].mean()/60, color='red', linestyle='--', label=f'Mean: {df[\"length_seconds\"].mean()/60:.2f} min')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Length of episodes over time\n",
    "plt.figure(figsize=(16, 6))\n",
    "# Filter out rows with missing dates for this plot\n",
    "temp_df = df.dropna(subset=['date', 'length_seconds'])\n",
    "temp_df = temp_df.sort_values('date')\n",
    "plt.scatter(temp_df['date'], temp_df['length_seconds']/60, alpha=0.6)\n",
    "plt.title('Episode Length Over Time', fontsize=14)\n",
    "plt.xlabel('Release Date', fontsize=12)\n",
    "plt.ylabel('Length (minutes)', fontsize=12)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.YearLocator())\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3. Release Schedule Analysis\n",
    "\n",
    "# Episodes per month over time\n",
    "if not df['date'].isnull().all():\n",
    "    df_with_date = df.dropna(subset=['date'])\n",
    "    df_with_date['year_month'] = df_with_date['date'].dt.to_period('M')\n",
    "    monthly_counts = df_with_date.groupby('year_month').size()\n",
    "    \n",
    "    plt.figure(figsize=(16, 6))\n",
    "    monthly_counts.plot(kind='bar')\n",
    "    plt.title('Number of Episodes Released per Month', fontsize=14)\n",
    "    plt.xlabel('Year-Month', fontsize=12)\n",
    "    plt.ylabel('Number of Episodes', fontsize=12)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Average episodes per day of week\n",
    "    df_with_date['day_of_week'] = df_with_date['date'].dt.day_name()\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    day_counts = df_with_date['day_of_week'].value_counts().reindex(day_order)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(x=day_counts.index, y=day_counts.values)\n",
    "    ax.bar_label(ax.containers[0])\n",
    "    plt.title('Number of Episodes by Day of Week', fontsize=14)\n",
    "    plt.xlabel('Day of Week', fontsize=12)\n",
    "    plt.ylabel('Number of Episodes', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4. Special Episodes Analysis\n",
    "\n",
    "# Proportion of special episodes\n",
    "plt.figure(figsize=(10, 6))\n",
    "special_counts = df['is_special'].value_counts()\n",
    "plt.pie(special_counts, labels=['Regular', 'Special'], autopct='%1.1f%%', startangle=90, colors=['#5D9CEC', '#FC6E51'])\n",
    "plt.title('Proportion of Special Episodes', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Special episodes by season\n",
    "special_by_season = df.groupby('season')['is_special'].sum()\n",
    "total_by_season = df.groupby('season').size()\n",
    "special_percent = (special_by_season / total_by_season * 100)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x=special_percent.index, y=special_percent.values)\n",
    "ax.bar_label(ax.containers[0], fmt='%.1f%%')\n",
    "plt.title('Percentage of Special Episodes by Season', fontsize=14)\n",
    "plt.xlabel('Season', fontsize=12)\n",
    "plt.ylabel('Percentage', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5. Title Analysis (Word Cloud)\n",
    "\n",
    "# If you have wordcloud installed\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    \n",
    "    # Combine all titles\n",
    "    all_titles = ' '.join(df['title'].dropna().astype(str))\n",
    "    \n",
    "    # Create and generate a word cloud image\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=100, \n",
    "                          contour_width=3, contour_color='steelblue').generate(all_titles)\n",
    "    \n",
    "    # Display the generated image\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title('Word Cloud of Episode Titles', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"WordCloud is not installed. To use this feature, run: pip install wordcloud\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6. URL Analysis\n",
    "\n",
    "# Video IDs from URLs\n",
    "df['video_id'] = df['url'].str.extract(r'watch\\?v=([^&]+)')\n",
    "\n",
    "# Number of videos in different playlists\n",
    "if 'index=' in str(df['url'].iloc[0]):\n",
    "    df['playlist_index'] = df['url'].str.extract(r'index=(\\d+)')\n",
    "    df['playlist_index'] = pd.to_numeric(df['playlist_index'], errors='coerce')\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.scatter(df['playlist_index'], df['length_seconds']/60, alpha=0.6)\n",
    "    plt.title('Episode Length by Playlist Position', fontsize=14)\n",
    "    plt.xlabel('Position in Playlist', fontsize=12)\n",
    "    plt.ylabel('Length (minutes)', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7. Correlation Analysis\n",
    "\n",
    "# Create a correlation dataframe with numeric columns\n",
    "corr_columns = ['season', 'length_seconds']\n",
    "if 'episode_number' in df.columns and df['episode_number'].notna().any():\n",
    "    corr_columns.append('episode_number')\n",
    "if 'playlist_index' in df.columns:\n",
    "    corr_columns.append('playlist_index')\n",
    "\n",
    "# Only proceed if we have at least two columns for correlation\n",
    "if len(corr_columns) >= 2:\n",
    "    corr_df = df[corr_columns].dropna()\n",
    "    \n",
    "    # Compute correlation matrix\n",
    "    corr_matrix = corr_df.corr()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "    plt.title('Correlation Matrix', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8. Time Series Analysis\n",
    "\n",
    "# Episodes over time\n",
    "if not df['date'].isnull().all():\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    # Create a date range from min to max date\n",
    "    df_date = df.dropna(subset=['date'])\n",
    "    date_range = pd.date_range(start=df_date['date'].min(), end=df_date['date'].max(), freq='M')\n",
    "    \n",
    "    # Count episodes per month\n",
    "    episodes_by_month = df_date.resample('M', on='date').size()\n",
    "    \n",
    "    # Plot\n",
    "    plt.plot(episodes_by_month.index, episodes_by_month.values, marker='o', linestyle='-')\n",
    "    plt.title('Number of Episodes Released Over Time', fontsize=14)\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Number of Episodes', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Cumulative episodes over time\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    cumulative = df_date.sort_values('date')\n",
    "    cumulative['cumulative_count'] = range(1, len(cumulative) + 1)\n",
    "    \n",
    "    plt.plot(cumulative['date'], cumulative['cumulative_count'])\n",
    "    plt.title('Cumulative Number of Episodes Over Time', fontsize=14)\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Total Episodes', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Advanced Analysis\n",
    "\n",
    "### 9. Seasonality Analysis\n",
    "\n",
    "if not df['date'].isnull().all():\n",
    "    # Set up figure layout\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Episodes by month of year\n",
    "    df_with_date = df.dropna(subset=['date'])\n",
    "    df_with_date['month'] = df_with_date['date'].dt.month\n",
    "    monthly_dist = df_with_date.groupby('month').size()\n",
    "    \n",
    "    month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    \n",
    "    # Ensure we have all months (fill missing with 0)\n",
    "    monthly_dist = monthly_dist.reindex(range(1, 13), fill_value=0)\n",
    "    \n",
    "    ax1.bar(range(1, 13), monthly_dist.values)\n",
    "    ax1.set_xticks(range(1, 13))\n",
    "    ax1.set_xticklabels(month_names)\n",
    "    ax1.set_title('Number of Episodes by Month of Year', fontsize=14)\n",
    "    ax1.set_ylabel('Number of Episodes', fontsize=12)\n",
    "    \n",
    "    # Episodes by year\n",
    "    df_with_date['year'] = df_with_date['date'].dt.year\n",
    "    yearly_dist = df_with_date.groupby('year').size()\n",
    "    \n",
    "    ax2.bar(yearly_dist.index, yearly_dist.values)\n",
    "    ax2.set_title('Number of Episodes by Year', fontsize=14)\n",
    "    ax2.set_xlabel('Year', fontsize=12)\n",
    "    ax2.set_ylabel('Number of Episodes', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 10. Episode Type Classification\n",
    "\n",
    "# Creating broader categories based on title patterns\n",
    "def categorize_episode(title):\n",
    "    if pd.isna(title):\n",
    "        return \"Unknown\"\n",
    "    title = str(title).lower()\n",
    "    \n",
    "    if any(term in title for term in ['novogodi≈°nji', 'nova godina']):\n",
    "        return \"New Year Special\"\n",
    "    elif any(term in title for term in ['bo≈æiƒá', 'bo≈æiƒáni']):\n",
    "        return \"Christmas Special\"\n",
    "    elif 'specijal' in title:\n",
    "        return \"Other Special\"\n",
    "    elif any(term in title for term in ['atmosfera', 'proslava', 'jubilej']):\n",
    "        return \"Behind the Scenes\"\n",
    "    elif 'intervju' in title:\n",
    "        return \"Interview\"\n",
    "    else:\n",
    "        return \"Regular Episode\"\n",
    "\n",
    "df['episode_category'] = df['title'].apply(categorize_episode)\n",
    "\n",
    "# Visualize episode categories\n",
    "cat_counts = df['episode_category'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x=cat_counts.index, y=cat_counts.values)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title('Distribution of Episode Categories', fontsize=14)\n",
    "plt.xlabel('Category', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare length by category\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(x='episode_category', y='length_seconds', data=df, showfliers=False)\n",
    "plt.title('Episode Length by Category', fontsize=14)\n",
    "plt.xlabel('Category', fontsize=12)\n",
    "plt.ylabel('Length (seconds)', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 11. Summary of Key Findings\n",
    "\n",
    "print(\"\\nSummary of Key Findings:\")\n",
    "print(f\"- Total number of episodes: {len(df)}\")\n",
    "print(f\"- Number of seasons: {df['season'].nunique()}\")\n",
    "print(f\"- Average episode length: {df['length_seconds'].mean()/60:.2f} minutes\")\n",
    "print(f\"- Shortest episode: {df['length_seconds'].min()/60:.2f} minutes\")\n",
    "print(f\"- Longest episode: {df['length_seconds'].max()/60:.2f} minutes\")\n",
    "print(f\"- Percentage of special episodes: {df['is_special'].mean()*100:.1f}%\")\n",
    "\n",
    "if not df['date'].isnull().all():\n",
    "    date_range = df.dropna(subset=['date'])\n",
    "    print(f\"- First episode date: {date_range['date'].min().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"- Last episode date: {date_range['date'].max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"- Total time span: {(date_range['date'].max() - date_range['date'].min()).days} days\")\n",
    "\n",
    "# Export clean data\n",
    "df.to_csv('dr≈æavni_posao_cleaned.csv', index=False)\n",
    "print(\"\\nCleaned data has been saved to 'dr≈æavni_posao_cleaned.csv'\")\n",
    "\n",
    "# Display conclusions\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"1. [This will be filled based on actual data patterns]\")\n",
    "print(\"2. [This will be filled based on actual data patterns]\")\n",
    "print(\"3. [This will be filled based on actual data patterns]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
